{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea33cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 15 candidates, totalling 120 fits\n",
      "[CV 1/8; 1/15] START mlpregressor__activation=logistic, mlpregressor__alpha=0.39638244598192873, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0043753219922104385, mlpregressor__max_iter=207, mlpregressor__solver=sgd\n",
      "[CV 1/8; 1/15] END mlpregressor__activation=logistic, mlpregressor__alpha=0.39638244598192873, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0043753219922104385, mlpregressor__max_iter=207, mlpregressor__solver=sgd;, score=(train=-0.510, test=-0.808) total time=  42.2s\n",
      "[CV 1/8; 2/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd\n",
      "[CV 1/8; 2/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd;, score=(train=-0.358, test=-0.762) total time= 1.3min\n",
      "[CV 5/8; 2/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd\n",
      "[CV 5/8; 2/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd;, score=(train=-0.429, test=-1.125) total time= 4.4min\n",
      "[CV 1/8; 4/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam\n",
      "[CV 1/8; 4/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam;, score=(train=-0.455, test=-0.712) total time=  12.8s\n",
      "[CV 2/8; 4/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam\n",
      "[CV 2/8; 4/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam;, score=(train=-0.548, test=-0.885) total time=  16.4s\n",
      "[CV 3/8; 4/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam\n",
      "[CV 3/8; 4/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam;, score=(train=-0.557, test=-0.708) total time=  31.2s\n",
      "[CV 4/8; 4/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam\n",
      "[CV 4/8; 4/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam;, score=(train=-0.573, test=-0.527) total time=  35.2s\n",
      "[CV 7/8; 4/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam\n",
      "[CV 7/8; 4/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam;, score=(train=-0.572, test=-0.711) total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasschroeder/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/8; 1/15] START mlpregressor__activation=logistic, mlpregressor__alpha=0.39638244598192873, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0043753219922104385, mlpregressor__max_iter=207, mlpregressor__solver=sgd\n",
      "[CV 2/8; 1/15] END mlpregressor__activation=logistic, mlpregressor__alpha=0.39638244598192873, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0043753219922104385, mlpregressor__max_iter=207, mlpregressor__solver=sgd;, score=(train=-0.562, test=-0.753) total time=  58.6s\n",
      "[CV 2/8; 2/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd\n",
      "[CV 2/8; 2/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd;, score=(train=-0.394, test=-0.990) total time= 2.1min\n",
      "[CV 2/8; 3/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam\n",
      "[CV 2/8; 3/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam;, score=(train=-0.399, test=-0.933) total time= 1.6min\n",
      "[CV 5/8; 3/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam\n",
      "[CV 5/8; 3/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam;, score=(train=-0.435, test=-1.011) total time= 3.1min\n",
      "[CV 6/8; 4/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam\n",
      "[CV 6/8; 4/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.24346326796176587, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006618138134673482, mlpregressor__max_iter=372, mlpregressor__solver=adam;, score=(train=-0.573, test=-0.556) total time=  58.4s\n",
      "[CV 2/8; 5/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.2192689653553746, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.01060865020291277, mlpregressor__max_iter=450, mlpregressor__solver=adam\n",
      "[CV 2/8; 5/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.2192689653553746, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.01060865020291277, mlpregressor__max_iter=450, mlpregressor__solver=adam;, score=(train=-0.438, test=-0.806) total time=  26.7s\n",
      "[CV 8/8; 5/15] START mlpregressor__activation=relu, mlpregressor__alpha=0.2192689653553746, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.01060865020291277, mlpregressor__max_iter=450, mlpregressor__solver=adam\n",
      "[CV 8/8; 5/15] END mlpregressor__activation=relu, mlpregressor__alpha=0.2192689653553746, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.01060865020291277, mlpregressor__max_iter=450, mlpregressor__solver=adam;, score=(train=-0.497, test=-0.620) total time=  55.8s\n",
      "[CV 7/8; 6/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.1978269067179032, mlpregressor__hidden_layer_sizes=(10, 10), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.008142710315157562, mlpregressor__max_iter=282, mlpregressor__solver=sgd\n",
      "[CV 7/8; 6/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.1978269067179032, mlpregressor__hidden_layer_sizes=(10, 10), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.008142710315157562, mlpregressor__max_iter=282, mlpregressor__solver=sgd;, score=(train=-0.496, test=-0.589) total time= 2.6min\n",
      "[CV 3/8; 1/15] START mlpregressor__activation=logistic, mlpregressor__alpha=0.39638244598192873, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0043753219922104385, mlpregressor__max_iter=207, mlpregressor__solver=sgd\n",
      "[CV 3/8; 1/15] END mlpregressor__activation=logistic, mlpregressor__alpha=0.39638244598192873, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0043753219922104385, mlpregressor__max_iter=207, mlpregressor__solver=sgd;, score=(train=-0.599, test=-0.688) total time= 1.4min\n",
      "[CV 3/8; 2/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd\n",
      "[CV 3/8; 2/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.12866757747522042, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0036994089462953797, mlpregressor__max_iter=274, mlpregressor__solver=sgd;, score=(train=-0.409, test=-1.171) total time= 3.2min\n",
      "[CV 4/8; 3/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam\n",
      "[CV 4/8; 3/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam;, score=(train=-0.435, test=-0.626) total time= 1.8min\n",
      "[CV 8/8; 3/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam\n",
      "[CV 8/8; 3/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.13133542008886878, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.0011635353535928586, mlpregressor__max_iter=240, mlpregressor__solver=adam;, score=(train=-0.452, test=-0.534) total time= 3.6min\n",
      "[CV 5/8; 6/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.1978269067179032, mlpregressor__hidden_layer_sizes=(10, 10), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.008142710315157562, mlpregressor__max_iter=282, mlpregressor__solver=sgd\n",
      "[CV 5/8; 6/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.1978269067179032, mlpregressor__hidden_layer_sizes=(10, 10), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.008142710315157562, mlpregressor__max_iter=282, mlpregressor__solver=sgd;, score=(train=-0.474, test=-0.945) total time= 1.5min\n",
      "[CV 7/8; 7/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.2652264950428184, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0010465259765697124, mlpregressor__max_iter=257, mlpregressor__solver=sgd\n",
      "[CV 7/8; 7/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.2652264950428184, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.0010465259765697124, mlpregressor__max_iter=257, mlpregressor__solver=sgd;, score=(train=-0.573, test=-0.667) total time= 2.9min\n",
      "[CV 3/8; 9/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.29277985902725956, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006783833057552133, mlpregressor__max_iter=277, mlpregressor__solver=sgd\n",
      "[CV 3/8; 9/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.29277985902725956, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006783833057552133, mlpregressor__max_iter=277, mlpregressor__solver=sgd;, score=(train=-0.441, test=-0.937) total time= 1.4min\n",
      "[CV 3/8; 10/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.37001387680640163, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.010132978759572496, mlpregressor__max_iter=311, mlpregressor__solver=adam\n",
      "[CV 3/8; 10/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.37001387680640163, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.010132978759572496, mlpregressor__max_iter=311, mlpregressor__solver=adam;, score=(train=-0.495, test=-1.023) total time=  36.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/8; 10/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.37001387680640163, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.010132978759572496, mlpregressor__max_iter=311, mlpregressor__solver=adam\n",
      "[CV 5/8; 10/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.37001387680640163, mlpregressor__hidden_layer_sizes=(20, 20), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.010132978759572496, mlpregressor__max_iter=311, mlpregressor__solver=adam;, score=(train=-0.518, test=-0.908) total time= 1.7min\n",
      "[CV 7/8; 11/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.23049331945704746, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006346897790604909, mlpregressor__max_iter=421, mlpregressor__solver=sgd\n",
      "[CV 7/8; 11/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.23049331945704746, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.006346897790604909, mlpregressor__max_iter=421, mlpregressor__solver=sgd;, score=(train=-0.560, test=-0.677) total time= 1.8min\n",
      "[CV 8/8; 12/15] START mlpregressor__activation=tanh, mlpregressor__alpha=0.22284979721780315, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.004170698353403942, mlpregressor__max_iter=425, mlpregressor__solver=sgd\n",
      "[CV 8/8; 12/15] END mlpregressor__activation=tanh, mlpregressor__alpha=0.22284979721780315, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=adaptive, mlpregressor__learning_rate_init=0.004170698353403942, mlpregressor__max_iter=425, mlpregressor__solver=sgd;, score=(train=-0.555, test=-0.588) total time= 3.2min\n",
      "[CV 2/8; 15/15] START mlpregressor__activation=logistic, mlpregressor__alpha=0.33814335039595605, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.009786707411750077, mlpregressor__max_iter=456, mlpregressor__solver=sgd\n",
      "[CV 2/8; 15/15] END mlpregressor__activation=logistic, mlpregressor__alpha=0.33814335039595605, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.009786707411750077, mlpregressor__max_iter=456, mlpregressor__solver=sgd;, score=(train=-0.554, test=-0.778) total time=  38.0s\n",
      "[CV 5/8; 15/15] START mlpregressor__activation=logistic, mlpregressor__alpha=0.33814335039595605, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.009786707411750077, mlpregressor__max_iter=456, mlpregressor__solver=sgd\n",
      "[CV 5/8; 15/15] END mlpregressor__activation=logistic, mlpregressor__alpha=0.33814335039595605, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.009786707411750077, mlpregressor__max_iter=456, mlpregressor__solver=sgd;, score=(train=-0.585, test=-0.896) total time=  51.3s\n",
      "[CV 8/8; 15/15] START mlpregressor__activation=logistic, mlpregressor__alpha=0.33814335039595605, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.009786707411750077, mlpregressor__max_iter=456, mlpregressor__solver=sgd\n",
      "[CV 8/8; 15/15] END mlpregressor__activation=logistic, mlpregressor__alpha=0.33814335039595605, mlpregressor__hidden_layer_sizes=(5, 5), mlpregressor__learning_rate=constant, mlpregressor__learning_rate_init=0.009786707411750077, mlpregressor__max_iter=456, mlpregressor__solver=sgd;, score=(train=-0.610, test=-0.635) total time=  44.9s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.stats as stats\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tuning import optimize_model\n",
    "\n",
    "# Initialize the MLPRegressor\n",
    "estimator = MLPRegressor()\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "hyperparameters = {\n",
    "    \"mlpregressor__hidden_layer_sizes\": [(5, 5), (10, 10), (20, 20)],\n",
    "    \"mlpregressor__activation\": ['tanh', 'relu', 'logistic'],\n",
    "    \"mlpregressor__solver\": ['sgd', 'adam'],\n",
    "    \"mlpregressor__alpha\": stats.uniform(0.1, 0.3),\n",
    "    \"mlpregressor__learning_rate\": ['constant', 'adaptive'],\n",
    "    \"mlpregressor__learning_rate_init\": stats.uniform(0.001, 0.01),\n",
    "    \"mlpregressor__max_iter\": stats.randint(200, 500)\n",
    "}\n",
    "\n",
    "# Define the path and filename for saving tuning results\n",
    "results_path = \"./tuning_results/tuning_MLP\"\n",
    "\n",
    "# Ensure the results_path exists\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "try:\n",
    "    # Call the optimize_model function with the defined parameters\n",
    "    optimize_model(estimator, hyperparameters, results_path, n_iter=15, parallel_jobs=-1, cyclic=True, basic=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model optimization: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
